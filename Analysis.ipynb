{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Evaluation of Sinusitis Surgery Recommendation\n",
    "\n",
    "# This script evaluates LLM clinical decision-making for sinusitis surgery.\n",
    "# The workflow is as follows:\n",
    "# 1.  Setup: Load libraries and configure API keys.\n",
    "# 2.  Data Loading: Load and combine multiple years of patient data from BigQuery.\n",
    "# 3.  Preprocessing: \n",
    "    # - Group all records by patient ID.\n",
    "    # - For each patient, create a sorted, longitudinal clinical note history.\n",
    "    # - Identify the date of surgery (if any) and exclude pre-operative/post-operative notes.\n",
    "    # - Censor any sentences mentioning surgical plans to create a \"blinded\" note for the LLM.\n",
    "    # - Aggregate all other clinical data (labs, meds, demographics).\n",
    "    # - Create a clean, flat DataFrame where each row is a unique patient.\n",
    "# 4.  LLM Analysis:\n",
    "#     - Generate a structured prompt for each case.\n",
    "#     - Send the prompt to the GPT-4 API and parse the JSON response.\n",
    "# 5.  Evaluation:\n",
    "#     - Compare the LLM's decision against actual surgery CPT codes.\n",
    "#     - Calculate accuracy, precision, recall, and F1-score.\n",
    "#     - Analyze the LLM's confidence on correct vs. incorrect predictions.\n",
    "# 6.  Output: Save the full results and a sample for human evaluation to CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17880c1b",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342dad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import openai\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# For progress bars\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "# For BigQuery access\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Open AI Authentication\n",
    "try:\n",
    "    with open(\"openai_key.txt\", \"r\") as f:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = f.read().strip()\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "except FileNotFoundError:\n",
    "    print(\"OpenAI key file not found. Make sure 'openai_key.txt' is in the directory,\")\n",
    "    # Exit if key is not found, as the script cannot proceed.\n",
    "    exit()\n",
    "\n",
    "def query_openai(prompt):\n",
    "    \"\"\"Sends a prompt to the GPT-4 model and returns the content of the response.\"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert otolaryngologist. Your task is to provide a surgical recommendation based on the provided patient data. Respond only in the requested JSON format.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with the OpenAI API: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading - Read in datasets from BigQuery\n",
    "# GCP Configuration\n",
    "PROJECT_ID = \"som-nero-phi-roxanad-entllm\"\n",
    "\n",
    "print(\"Connecting to BigQuery to load datasets...\")\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# List of datasets to be combined\n",
    "DATASET_IDS = [\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2016',\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2017',\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2018',\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2019',\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2020_21',\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2022_23',\n",
    "    'starr_phi_confidential_stride_79984_ChronicSinusitis_2024_25',\n",
    "]\n",
    "\n",
    "# Name of tables to load from each dataset\n",
    "DATA_TABLES = [\n",
    "    'demographics',\n",
    "    'clinical_note',\n",
    "    'procedures',\n",
    "    'labs',\n",
    "    'med_orders',\n",
    "    'radiology_report'\n",
    "]\n",
    "\n",
    "# Create dictionary to hold dataframes\n",
    "dataframes = {}\n",
    "\n",
    "for table_name in DATA_TABLES:\n",
    "     print(f\"Loading and unioning table: '{table_name}'...\")\n",
    "     try:\n",
    "        # Construct a query to UNION this specific table across all yearly datasets\n",
    "        union_query = \"\\nUNION ALL\\n\".join(\n",
    "            [f\"SELECT * FROM `{PROJECT_ID}.{dataset_id}.{table_name}`\" for dataset_id in DATASET_IDS]\n",
    "        )\n",
    "        # Load the data and store it in our dictionary\n",
    "        dataframes[table_name] = client.query(union_query).to_dataframe()\n",
    "        print(f\" -> Loaded {len(dataframes[table_name])} total rows for '{table_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- QUERY FAILED for table '{table_name}' ---\")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Please check that this table exists in all of your yearly datasets.\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff51fc",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing - Setup\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Define keywords and CPT codes for efficient searching\n",
    "SURGERY_CPT_CODES = {\n",
    "    '31253', '31254', '31255', '31256', '31257', '31259', '31267',\n",
    "    '31276', '31287', '31288', '31240'\n",
    "}\n",
    "LAB_KEYWORDS = {'cbc', 'eosinophil count', 'eosinophil %', 'bmp', 'cmp', 'ige', 'igg', 'iga', 'igm', 'sinus culture', 'nasal culture'}\n",
    "MED_KEYWORDS = {\n",
    "    'amoxicillin', 'amoxicillin-clavulanate', 'doxycycline', 'trimethoprim-sulfamethoxazole', 'clindamycin',\n",
    "    'levofloxacin', 'cefdinir', 'moxifloxacin', 'cefuroxime', 'azithromycin', 'mupirocin', 'gentamicin',\n",
    "    'tobramycin', 'vancomycin', 'prednisone', 'methylprednisone', 'dexamethasone', 'budesonide',\n",
    "    'mometasone', 'fluticasone', 'azelastine', 'saline rinse'\n",
    "}\n",
    "DIAGNOSTIC_ENDOSCOPY_CPT_CODES = {'31231', '31237'}\n",
    "\n",
    "def censor_surgical_plans(text):\n",
    "    \"\"\"Censors sentences containing surgical plans or recommendations.\"\"\"\n",
    "    import re\n",
    "    if not isinstance(text, str): return text  # Ensure input is a string\n",
    "    text = text.lower()  # Normalize to lowercase for keyword matching\n",
    "    # Define keywords that indicate surgical plans or recommendations\n",
    "    censor_keywords = ['surgery', 'fess', 'ess', 'operative', 'operation', 'surgical', 'recommend proceeding with', 'plan for', 'schedule', 'consent for']\n",
    "    # Split text into sentences and filter out those containing any of the keywords\n",
    "    # This regex splits on sentence-ending punctuation followed by whitespace\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    censored_sentences = [s for s in sentences if not any(kw in s.lower() for kw in censor_keywords)]\n",
    "    return \" \".join(censored_sentences)\n",
    "\n",
    "# Helper functions for parsing nested data\n",
    "\n",
    "def extract_ent_notes(notes_list):\n",
    "    \"\"\"Extracts text from relevant ENT outpatient progress notes.\"\"\"\n",
    "    if not isinstance(notes_list, list): return \"\"\n",
    "    ent_notes_text = []\n",
    "    for note in notes_list:\n",
    "        note_type = note.get('type', '').lower()\n",
    "        author = note.get('author', '').lower()\n",
    "        text = note.get('text', '').lower()\n",
    "        if \"progress note, outpatient\" in note_type and ('ent' in author or 'otolaryngology' in author or 'ent' in text or 'otolaryngology' in text):\n",
    "            ent_notes_text.append(note.get('text', ''))\n",
    "    return \"\\n---\\n\".join(ent_notes_text)\n",
    "\n",
    "def check_list_for_keywords(items, key_name, keywords):\n",
    "    \"\"\"Generic function to check if any keyword exists in a list of dictionaries.\"\"\"\n",
    "    if not isinstance(items, list): return False\n",
    "    return any(keyword in str(item.get(key_name, '')).lower() for item in items for keyword in keywords)\n",
    "\n",
    "def process_procedures(procedures_list):\n",
    "    \"\"\"Checks for specific diagnostic and surgical CPT codes.\"\"\"\n",
    "    if not isinstance(procedures_list, list): return False, False\n",
    "    had_surgery = False\n",
    "    had_endoscopy = False\n",
    "    for proc in procedures_list:\n",
    "        if proc.get('code_type') == 'CPT':\n",
    "            code = proc.get('code')\n",
    "            if code in SURGERY_CPT_CODES:\n",
    "                had_surgery = True\n",
    "            if code in DIAGNOSTIC_ENDOSCOPY_CPT_CODES:\n",
    "                had_endoscopy = True\n",
    "    return had_surgery, had_endoscopy\n",
    "\n",
    "\n",
    "def extract_radiology_report(reports_list):\n",
    "    \"\"\"Extracts text from relevant sinus CT reports.\"\"\"\n",
    "    if not isinstance(reports_list, list): return \"\"\n",
    "    report_texts = []\n",
    "    for report in reports_list:\n",
    "        report_type = str(report.get('type', '')).lower()\n",
    "        title = str(report.get('title', '')).lower()\n",
    "        # Ensure we only include relevant CT reports of the sinuses\n",
    "        if 'ct' in report_type and ('sinus' in title or 'paranasal' in title or 'nasal' in title):\n",
    "            report_texts.append(report.get('text', ''))\n",
    "    return \"\\n---\\n\".join(filter(None, report_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753176ee",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing - Main Processing Loop\n",
    "\n",
    "processed_patient_records = []\n",
    "\n",
    "# Get a unique list of all patients from the demographics table\n",
    "unique_patient_ids = dataframes['demographics']['patient_id'].unique()\n",
    "\n",
    "for patient_id in tqdm(unique_patient_ids, desc=\"Processing Patients\"):\n",
    "    # --- Fetch all records for this specific patient from each table ---\n",
    "    patient_notes = dataframes['clinical_note'][dataframes['clinical_note']['patient_id'] == patient_id]\n",
    "    patient_procedures = dataframes['procedures'][dataframes['procedures']['patient_id'] == patient_id]\n",
    "    patient_labs = dataframes['labs'][dataframes['labs']['patient_id'] == patient_id]\n",
    "    patient_meds = dataframes['med_orders'][dataframes['med_orders']['patient_id'] == patient_id]\n",
    "    patient_radiology = dataframes['radiology_report'][dataframes['radiology_report']['patient_id'] == patient_id]\n",
    "    patient_demographics = dataframes['demographics'][dataframes['demographics']['patient_id'] == patient_id].iloc[-1] # Most recent record\n",
    "\n",
    "    # --- Perform the longitudinal logic ---\n",
    "    # Sort notes by date to create the history\n",
    "    all_notes_sorted = patient_notes.sort_values(by='date', ascending=True)\n",
    "\n",
    "    # Find the earliest surgery date for this patient\n",
    "    earliest_surgery_date = pd.NaT\n",
    "    surgeries = patient_procedures[patient_procedures['code'].isin(SURGERY_CPT_CODES)]\n",
    "    if not surgeries.empty:\n",
    "        earliest_surgery_date = pd.to_datetime(surgeries['date']).min()\n",
    "        \n",
    "    # Filter notes to only those occurring BEFORE the surgery\n",
    "    if pd.notna(earliest_surgery_date):\n",
    "        notes_for_llm_df = all_notes_sorted[pd.to_datetime(all_notes_sorted['date']) < earliest_surgery_date]\n",
    "    else:\n",
    "        notes_for_llm_df = all_notes_sorted\n",
    "\n",
    "    # Filter for relevant ENT progress notes\n",
    "    ent_notes_mask = notes_for_llm_df['type'].str.contains(\"progress note, outpatient\", case=False, na=False) & \\\n",
    "                     (notes_for_llm_df['author'].str.contains(\"ent|otolaryngology\", case=False, na=False) | \\\n",
    "                      notes_for_llm_df['text'].str.contains(\"ent|otolaryngology\", case=False, na=False))\n",
    "    \n",
    "    final_ent_notes = notes_for_llm_df[ent_notes_mask]\n",
    "\n",
    "    if final_ent_notes.empty:\n",
    "        continue # Skip patient if they have no relevant notes before the decision point\n",
    "\n",
    "    # Combine and censor notes\n",
    "    longitudinal_summary = \"\\n---\\n\".join(final_ent_notes['text'].dropna())\n",
    "    censored_summary = censor_surgical_plans(longitudinal_summary)\n",
    "    \n",
    "    # ***FIXED***: Use the helper function to properly filter for relevant CT Sinus reports\n",
    "    radiology_text = extract_radiology_report(patient_radiology.to_dict('records'))\n",
    "\n",
    "    # Combine data for individual patient\n",
    "    processed_patient_records.append({\n",
    "        'patient_id': patient_id,\n",
    "        'age': patient_demographics.get('age'), 'race': patient_demographics.get('race'),\n",
    "        'ethnicity': patient_demographics.get('ethnicity'), 'sex': patient_demographics.get('legal_sex'),\n",
    "        'longitudinal_summary_statement': longitudinal_summary,\n",
    "        'censored_summary_statement': censored_summary,\n",
    "        'radiology_text': radiology_text,\n",
    "        'has_radiology_report': bool(radiology_text),\n",
    "        'Had_Surgery': pd.notna(earliest_surgery_date),\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38257faf",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing - New, Clean DataFrame!\n",
    "\n",
    "cases_df = pd.DataFrame(processed_patient_records)\n",
    "cases_df['case_index'] = cases_df.index\n",
    "print(f\"\\nPreprocessing complete. Created {len(cases_df)} unique patient longitudinal records.\")\n",
    "\n",
    "# Report on filtering results\n",
    "initial_patient_count = len(unique_patient_ids)\n",
    "final_patient_count = len(cases_df)\n",
    "excluded_cases = initial_patient_count - final_patient_count\n",
    "\n",
    "print(f\"\\nPreprocessing complete.\")\n",
    "print(f\"Started with {initial_patient_count} unique patients.\")\n",
    "print(f\"Excluded {excluded_cases} records that did not meet criteria (e.g., no relevant pre-decision ENT notes).\")\n",
    "print(f\"Created a clean dataset with {final_patient_count} valid patient cases for evaluation.\")\n",
    "print(f\"Cases with relevant radiology reports: {cases_df['has_radiology_report'].sum()}\")\n",
    "print(f\"Cases with recorded surgery: {cases_df['Had_Surgery'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab1d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis - Prompt Engineering\n",
    "\n",
    "def generate_prompt(case):\n",
    "    \n",
    "    radiology_section = f\"- Radiology Report: {case['radiology_text']}\" if case['has_radiology_report'] else \"- Radiology Report: Not available.\"\n",
    "\n",
    "    \"\"\"Generates a structured prompt for the LLM.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert otolaryngologist evaluating a case of chronic sinusitis.\n",
    "    Based ONLY on the information provided below, make a recommendation on sinus surgery.\n",
    "\n",
    "    --- Case Details ---\n",
    "    - Case Index: {case['case_index']}\n",
    "    - Age: {case['age']}\n",
    "    - Sex: {case['sex']}\n",
    "    - Censored Clinical Summary from ENT Notes: {case['censored_summary_statement']}\n",
    "    {radiology_section}\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Provide your response as a JSON object with three keys:\n",
    "    1. \"decision\": Your recommendation, either \"Yes\" or \"No\".\n",
    "    2. \"confidence\": Your confidence level from 1 (not confident) to 10 (very confident).\n",
    "    3. \"reasoning\": A brief, 2-4 sentence explanation for your decision.\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0967b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis - Feed the data into OpenAI's model for evaluation - documented procedure)\n",
    "print(\"\\nStarting LLM evaluation for each case...\")\n",
    "results = []\n",
    "\n",
    "# Iterate over the single, consolidated dataframe\n",
    "for index, case in tqdm(cases_df.iterrows(), total=len(cases_df), desc=\"Evaluating Cases\"):\n",
    "    prompt = generate_prompt(case)\n",
    "    response_text = query_openai(prompt)\n",
    "\n",
    "    # Parse the JSON response and handle errors\n",
    "    if response_text:\n",
    "        try:\n",
    "            # Clean potential markdown formatting\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0]\n",
    "            llm_output = json.loads(response_text)\n",
    "            results.append({\n",
    "                'case_index': case['case_index'],\n",
    "                'llm_decision': llm_output.get('decision', 'Error'),\n",
    "                'llm_confidence': llm_output.get('confidence', 0),\n",
    "                'llm_reasoning': llm_output.get('reasoning', 'Parsing Error'),\n",
    "            })\n",
    "        except (json.JSONDecodeError, AttributeError):\n",
    "            results.append({'case_index': case['case_index'], 'llm_decision': 'Error', 'llm_confidence': 0, 'llm_reasoning': f\"Parsing Failed: {response_text}\"})\n",
    "    else: # Handle API call failures\n",
    "         results.append({'case_index': case['case_index'], 'llm_decision': 'Error', 'llm_confidence': 0, 'llm_reasoning': \"API Call Failed\"})\n",
    "\n",
    "# Merge LLM results back into the main DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "cases_df = pd.merge(cases_df, results_df, on='case_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e065b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis - Evaluation Metrics\n",
    "\n",
    "# Create a clean dataframe for evaluation, excluding any cases that had API/parsing errors.\n",
    "eval_df = cases_df[cases_df['llm_decision'].isin(['Yes', 'No'])].copy()\n",
    "\n",
    "if not eval_df.empty:\n",
    "    print(\"\\n--- LLM Performance Evaluation ---\")\n",
    "\n",
    "    # Map LLM decision ('Yes'/'No') to boolean for comparison. Using .lower() is robust.\n",
    "    eval_df['llm_decision_bool'] = eval_df['llm_decision'].str.lower() == 'yes'\n",
    "\n",
    "    #  Use 'Had_Surgery' (the correct column name) for comparison\n",
    "    y_true = eval_df['Had_Surgery']\n",
    "    y_pred = eval_df['llm_decision_bool']\n",
    "\n",
    "    # Accuracy, Classification Report, and Confusion Matrix\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Overall Accuracy: {accuracy:.2%}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['No Surgery', 'Surgery'], zero_division=0))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    # --- Confidence Analysis ---\n",
    "    eval_df['is_correct'] = (y_true == y_pred)\n",
    "    \n",
    "    print(\"\\n--- Confidence Analysis ---\")\n",
    "    print(f\"Average confidence on CORRECT predictions: {eval_df[eval_df['is_correct']]['llm_confidence'].mean():.2f}\")\n",
    "    print(f\"Average confidence on INCORRECT predictions: {eval_df[~eval_df['is_correct']]['llm_confidence'].mean():.2f}\")\n",
    "\n",
    "    # Break down confidence by prediction outcome (TP, TN, FP, FN)\n",
    "    tp_mask = (eval_df['is_correct']) & (eval_df['Had_Surgery'])\n",
    "    tn_mask = (eval_df['is_correct']) & (~eval_df['Had_Surgery'])\n",
    "    fp_mask = (~eval_df['is_correct']) & (eval_df['llm_decision_bool'])\n",
    "    fn_mask = (~eval_df['is_correct']) & (~eval_df['llm_decision_bool'])\n",
    "\n",
    "    print(\"\\n--- Average Confidence by Prediction Outcome ---\")\n",
    "    print(f\"True Positives (Correctly recommended surgery):  {eval_df.loc[tp_mask, 'llm_confidence'].mean():.2f}\")\n",
    "    print(f\"True Negatives (Correctly recommended no surgery): {eval_df.loc[tn_mask, 'llm_confidence'].mean():.2f}\")\n",
    "    print(f\"False Positives (Wrongly recommended surgery):   {eval_df.loc[fp_mask, 'llm_confidence'].mean():.2f}\")\n",
    "    print(f\"False Negatives (Missed needed surgery):       {eval_df.loc[fn_mask, 'llm_confidence'].mean():.2f}\")\n",
    "\n",
    "    # Plotting confidence distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    eval_df['llm_confidence'].hist(bins=np.arange(0.5, 11.5, 1), edgecolor='black', rwidth=0.8)\n",
    "    plt.title('Distribution of LLM Confidence Scores')\n",
    "    plt.xlabel('Confidence Score (1-10)')\n",
    "    plt.ylabel('Number of Cases')\n",
    "    plt.xticks(range(1, 11))\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo cases were successfully evaluated by the LLM. Cannot generate performance metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9677a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final complete dataframe to a CSV file.\n",
    "full_results_path = \"sinusitis_llm_full_results.csv\"\n",
    "cases_df.to_csv(full_results_path, index=False)\n",
    "print(f\"\\nFull results with all columns saved to '{full_results_path}'\")\n",
    "\n",
    "# Save a sample of 200 cases to a separate CSV for human evaluation.\n",
    "if len(cases_df) > 0:\n",
    "    sample_path = \"sinusitis_llm_human_review_sample.csv\"\n",
    "    # Ensure we don't try to sample more rows than exist\n",
    "    sample_size = min(200, len(cases_df))\n",
    "    cases_df.head(sample_size).to_csv(sample_path, index=False)\n",
    "    print(f\"A sample of {sample_size} cases for human review saved to '{sample_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
